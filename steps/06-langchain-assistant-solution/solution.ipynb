{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain - Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../img/installation-ico.png) Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install langchain langchain-community wikipedia faiss-cpu chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../img/package-ico.png) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../img/parametrage-ico.png) Paramétrages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global embeddings_flag\n",
    "embeddings_flag = False\n",
    "\n",
    "model = \"mistral\"\n",
    "chat = ChatOllama(temperature=0, model=model)\n",
    "messages = [SystemMessage(content=\"Toute réponse devra être faîtes en Français.\")]\n",
    "wiki = WikipediaQueryRun(\n",
    "    api_wrapper=WikipediaAPIWrapper(\n",
    "        lang=\"fr\", top_k_results=1, doc_content_chars_max=10000\n",
    "    )\n",
    ")\n",
    "# wiki.validate_environment({\"lang\":\"fr\"})\n",
    "# wikipedia.set_lang(\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de l'appel à wikipedia\n",
    "def get_wiki(search):\n",
    "\n",
    "    return wiki.run(search).split(\"\\n\\n\")\n",
    "    # Issue with auto_suggest\n",
    "    summary = wikipedia.summary(title=search, sentences=5, auto_suggest=False)\n",
    "\n",
    "    # create URL based on user input and language\n",
    "    url = f\"https://fr.wikipedia.org/wiki/{search}\"\n",
    "\n",
    "    # send GET request to URL and parse HTML content\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # extract main content of page\n",
    "    content_div = soup.find(id=\"mw-content-text\")\n",
    "\n",
    "    # extract all paragraphs of content\n",
    "    paras = content_div.find_all(\"p\")\n",
    "\n",
    "    # concatenate paragraphs into full page content\n",
    "    full_page_content = \"\"\n",
    "    for para in paras:\n",
    "        full_page_content += para.text\n",
    "\n",
    "    # print the full page content\n",
    "    return full_page_content, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestion de l'index vectoriel\n",
    "def build_index(wiki_content):\n",
    "    print(\"building index .....\")\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "    texts = text_splitter.split_text(wiki_content)\n",
    "    embeddings = OllamaEmbeddings(model=model, num_gpu=1)\n",
    "    docsearch = Chroma.from_texts(texts, embeddings)\n",
    "    # docsearch = FAISS.from_texts(texts, embeddings)\n",
    "    # with open(\"./embeddings.pkl\", \"wb\") as f:\n",
    "    #     pickle.dump(docsearch, f)\n",
    "\n",
    "    return embeddings, docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envoi de la requête au chatbot\n",
    "def get_chatbot_response(user_query, index):\n",
    "    docs = index.similarity_search(user_query)\n",
    "    # docs = index.similarity_search(user_query, K=6)\n",
    "    main_content = user_query + \"\\n\\n\"\n",
    "    for doc in docs:\n",
    "        main_content += doc.page_content + \"\\n\\n\"\n",
    "    messages.append(HumanMessage(content=main_content))\n",
    "    ai_response = chat(messages).content\n",
    "    messages.pop()\n",
    "    messages.append(HumanMessage(content=user_query))\n",
    "    messages.append(AIMessage(content=ai_response))\n",
    "\n",
    "    return ai_response\n",
    "\n",
    "\n",
    "# Affichage des messages\n",
    "def display_messages(all_messages):\n",
    "    for msg in all_messages:\n",
    "        if msg[\"user\"] == \"user\":\n",
    "            print(\n",
    "                f\"You ({msg['time']}): {msg['text']}\",\n",
    "            )\n",
    "        else:\n",
    "            print(f\"IA-Bot ({msg['time']}): {msg['text']}\")\n",
    "\n",
    "\n",
    "# Envoi des messages au chatbot\n",
    "def send_message(user_query, index, all_messages):\n",
    "    if user_query:\n",
    "        all_messages.append(\n",
    "            {\n",
    "                \"user\": \"user\",\n",
    "                \"time\": datetime.now().strftime(\"%H:%M\"),\n",
    "                \"text\": user_query,\n",
    "            }\n",
    "        )\n",
    "        bot_response = get_chatbot_response(user_query, index)\n",
    "        all_messages.append(\n",
    "            {\n",
    "                \"user\": \"bot\",\n",
    "                \"time\": datetime.now().strftime(\"%H:%M\"),\n",
    "                \"text\": bot_response,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../img/jouer-ico.png) Exécution(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messages à transmettre\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"Vous êtes un robot Question/Réponse et vous répondez à toutes les questions posées par l'utilisateur. Si vous ne connaissez pas la réponse, indiquez 'Désolé, je ne sais pas'.\"\n",
    "    )\n",
    "]\n",
    "# Stockage de la discussion\n",
    "all_messages = []\n",
    "\n",
    "search = input(\"Qu'avez-vous en tête ?\")\n",
    "# search = \"La ville de Nantes\"\n",
    "\n",
    "if len(search):\n",
    "    wiki_content = get_wiki(search)\n",
    "\n",
    "    if len(wiki_content):\n",
    "        try:\n",
    "            # Create input text box for user to send messages\n",
    "            print(f\"First doc: {wiki_content[0]}\")\n",
    "            user_query = input(\"You: \")\n",
    "            # user_query = \"Quel est le nombre d'habitant\"\n",
    "\n",
    "            if not embeddings_flag:\n",
    "                embeddings, docsearch = build_index(\"\\n\\n\".join(wiki_content))\n",
    "                embeddings_flag = True\n",
    "                # with open(\"./embeddings.pkl\", 'rb') as f:\n",
    "                #     index = pickle.load(f)\n",
    "                index = docsearch\n",
    "\n",
    "            if embeddings_flag:\n",
    "                send_message(user_query, index, all_messages)\n",
    "                display_messages(all_messages)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                \"ERROR: quelque chose ne va pas... veuillez réessayer\", file=sys.stderr\n",
    "            )\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-shool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
