{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/installation-ico.png) Installation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install langchain langchain-google-vertexai google.auth python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/package-ico.png) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.auth\n",
    "\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "# pour le template du prompt d'entrée\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# pour le parser de sortie\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/parametrage-ico.png) Paramétrages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestion credentials VertexAI\n",
    "%load_ext dotenv\n",
    "\n",
    "print(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\n",
    "\n",
    "google.auth.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notre modèle\n",
    "llm = VertexAI(model_name=\"gemini-1.0-pro\", temperature=0)\n",
    "\n",
    "# notre prompt de chat\n",
    "prompt = PromptTemplate.from_template(\"Tell me a joke about {input}.\")\n",
    "# notre parser de sortie\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# notre chaîne d'exécution\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/jouer-ico.png) Exécution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invocation simple\n",
    "input = \"a baker\"\n",
    "chain.invoke({\"input\": input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aller plus loin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/jouer-ico.png) Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invocation pour stream\n",
    "for chunk in chain.stream({\"input\": input}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/jouer-ico.png) Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.batch([\n",
    "    {\"input\": \"developers\"},\n",
    "    {\"input\": \"magician\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/jouer-ico.png) ChatPrompt et JsonParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from pprint import pprint\n",
    "\n",
    "# Le LLM\n",
    "llm = ChatVertexAI(model_name=\"gemini-1.5-pro\", temperature=0)\n",
    "\n",
    "# Le schéma de données attendu en sortie\n",
    "class Response(BaseModel):\n",
    "    answer: str = Field(description=\"answer to the user's question\")\n",
    "    source: str = Field(description=\"source used to answer the user's question, should be a website\")\n",
    "\n",
    "# Le parser avec le schéma\n",
    "json_parser = JsonOutputParser(pydantic_object=Response)\n",
    "\n",
    "format_instructions = json_parser.get_format_instructions()\n",
    "\n",
    "# Le ChatPromptTemplate\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # Message système pour spécifier le comportement ainsi que le format de sortie\n",
    "        SystemMessage(content=(f\"\"\"Answer the users question as best as possible.\n",
    "        {format_instructions}\n",
    "        \"\"\")),\n",
    "        \n",
    "        # Message humain à partir d'un template\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chaînage\n",
    "chain_chat = chat_prompt | llm | json_parser\n",
    "\n",
    "question = \"What is the capital of Norway?\"\n",
    "\n",
    "# FACTULTATIF : Affichage du prompt\n",
    "pprint(chat_prompt.format_messages(question=question))\n",
    "\n",
    "chain_chat.invoke({\"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv.school",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
