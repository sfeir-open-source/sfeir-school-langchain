{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/installation-ico.png) Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install langchain langchain-community langchain-google-vertexai google.auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/package-ico.png) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.auth\n",
    "\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.callbacks.base import BaseCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/parametrage-ico.png) Paramétrages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestion credentials VertexAI\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../../settings/credentials.json\"\n",
    "google.auth.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Any, Dict\n",
    "models = [ \"gemini-1.5-pro\", \"text-bison\", \"text-unicorn\" ]\n",
    "\n",
    "class MyHandler(BaseCallbackHandler):\n",
    "    def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts, metadata, **kwargs\n",
    "    ):\n",
    "        print(f\"\\non_llm_start {metadata['name']}\")\n",
    "        \n",
    "    def on_llm_end(\n",
    "        self, response, **kwargs\n",
    "    ):\n",
    "        print(f\"on_llm_end\")\n",
    "\n",
    "    def on_llm_error(\n",
    "        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when LLM errors.\"\"\"\n",
    "        print(\"Got error while running :\", error)\n",
    "\n",
    "    def on_chain_start(\n",
    "        self, serialized: Dict[str, Any], inputs: Dict[str, Any], metadata, **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"on_chain_start {metadata['name']}\")\n",
    "        \n",
    "    def on_chain_end(\n",
    "        self, serialized: Dict[str, Any], inputs: Dict[str, Any], metadata, **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"on_chain_end {metadata['name']}\")\n",
    "\n",
    "llm = VertexAI(\n",
    "    model_name=\"text-bison\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "llms = [ VertexAI(model_name=m, callbacks=[MyHandler()], metadata={\"name\": m}) for m in models]\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Tell me a joke about {input}.\"\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chains = [prompt | llm | output_parser for llm in llms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](../../img/jouer-ico.png) Exécution(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"elephant\"\n",
    "for c in chains:\n",
    "    for s in c.invoke({\"input\": input}):\n",
    "        print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model_name will become a required arg for VertexAIEmbeddings starting from Sep-01-2024. Currently the default is set to chat-bison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\" LangChain est un modèle de langage qui peut générer du texte en français. Il a été développé par l'équipe de recherche en intelligence artificielle de Google. LangChain est capable de générer du texte cohérent et grammaticalement correct, et il peut également traduire des langues.\" response_metadata={'is_blocked': False, 'errors': (), 'safety_attributes': [{'Finance': 0.1, 'Insult': 0.2, 'Sexual': 0.1}], 'grounding_metadata': {'citations': [], 'search_queries': []}, 'usage_metadata': {'candidates_billable_characters': 238.0, 'candidates_token_count': 55.0, 'prompt_billable_characters': 20.0, 'prompt_token_count': 7.0}} id='run-70f1bf9a-6ce1-41f4-bf4f-a685707472aa-0' usage_metadata={'input_tokens': 7, 'output_tokens': 55, 'total_tokens': 62}\n",
      "Calling with  {'llm': 'gemini-1.5-pro'}\n",
      "content=\" LangChain est un modèle de langage qui peut générer du texte en français. Il a été développé par l'équipe de recherche en intelligence artificielle de Google. LangChain est capable de générer du texte cohérent et grammaticalement correct, et il peut également traduire des langues étrangères en français.\" response_metadata={'is_blocked': False, 'errors': (), 'safety_attributes': [{'Finance': 0.1, 'Insult': 0.2, 'Sexual': 0.1}], 'grounding_metadata': {'citations': [], 'search_queries': []}, 'usage_metadata': {'candidates_billable_characters': 258.0, 'candidates_token_count': 58.0, 'prompt_billable_characters': 20.0, 'prompt_token_count': 7.0}} id='run-deeb451c-df50-45c5-ba26-58b1c3b4e08d-0' usage_metadata={'input_tokens': 7, 'output_tokens': 58, 'total_tokens': 65}\n",
      "Calling with  {'llm': 'gemini_old'}\n",
      "content='Bien sûr! \\n\\nJe suis un grand modèle linguistique, entraîné par Google.\\n\\nLangChain est une bibliothèque open source pour construire des applications d\\'IA \"sur mesure\" en utilisant une programmation déclarative. \\n\\nAu lieu d\\'écrire du code impératif pas à pas, vous écrivez simplement la logique de la manière dont vous voulez que votre application fonctionne, et LangChain s\\'occupe de générer l\\'IA et le code nécessaires pour réaliser cette logique. Il utilise l\\'apprentissage par renforcement de l\\'apprentissage profond (RLHF) pour mettre au point des modèles qui fonctionnent dans le contexte de vos propres données et de vos propres exigences sans qu\\'il soit nécessaire de les étiqueter ou de les annoter. \\n\\nEn substance, LangChain vous permet de créer des applications basées sur l\\'IA en définissant ce que vous voulez qu\\'elles fassent en langage naturel, plutôt qu\\'en écrivant du code. Il est toujours en phase de développement, mais il montre un grand potentiel pour simplifier le développement des applications basées sur l\\'IA et les rendre plus accessibles à un public plus large.' response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 49, 'candidates_token_count': 232, 'total_token_count': 281}, 'finish_reason': 'STOP'} id='run-30a0c2cb-aba4-4071-8e49-e96d20f02393-0' usage_metadata={'input_tokens': 49, 'output_tokens': 232, 'total_tokens': 281}\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatVertexAI().configurable_alternatives(\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    default_key=\"gemini-1.5-pro\",\n",
    "    # Ajout des autres options associées à d'autre clé\n",
    "    gemini_old=ChatVertexAI(model_name=\"gemini-1.0-pro\")\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"\"\"En tant qu'assistant IA, avant toute réponse indique absolument qui tu es et le nom de ton modèle.\n",
    "                  Uniquement et seulement après, tu peux répondre à la demande de l'utilisateur\n",
    "                  \"\"\"),\n",
    "    HumanMessage(content=\"Parle moi de LangChain.\")\n",
    "    ])\n",
    "chain = prompt | llm\n",
    "\n",
    "print(chain.invoke({}), end=\"\\n\")\n",
    "\n",
    "configs = [{\"llm\": m} for m in [\"gemini-1.5-pro\", \"gemini_old\"]]\n",
    "for c in configs:\n",
    "    print(\"Calling with \", c)\n",
    "    print(chain.with_config(configurable=c).invoke({}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvSchool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
